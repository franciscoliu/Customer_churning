{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b312ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import xgboost as xgb\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, plot_confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc, plot_precision_recall_curve\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390409a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv(\"BankChurners.csv\").drop(columns = ['CLIENTNUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c7f314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2.061106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attrition_Flag  Customer_Age  Dependent_count  Education_Level  \\\n",
       "0                   0            45                3         1.000000   \n",
       "1                   0            49                5         3.000000   \n",
       "2                   0            51                3         3.000000   \n",
       "3                   0            40                4         1.000000   \n",
       "4                   0            40                3         0.000000   \n",
       "...               ...           ...              ...              ...   \n",
       "10122               0            50                2         3.000000   \n",
       "10123               1            41                2         2.061106   \n",
       "10124               1            44                1         1.000000   \n",
       "10125               1            30                2         3.000000   \n",
       "10126               1            43                2         3.000000   \n",
       "\n",
       "       Income_Category  Card_Category  Months_on_book  \\\n",
       "0                  2.0              0              39   \n",
       "1                  0.0              0              44   \n",
       "2                  3.0              0              36   \n",
       "3                  0.0              0              34   \n",
       "4                  2.0              0              21   \n",
       "...                ...            ...             ...   \n",
       "10122              1.0              0              40   \n",
       "10123              1.0              0              25   \n",
       "10124              0.0              0              36   \n",
       "10125              1.0              0              36   \n",
       "10126              0.0              1              25   \n",
       "\n",
       "       Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                             5                       1   \n",
       "1                             6                       1   \n",
       "2                             4                       1   \n",
       "3                             3                       4   \n",
       "4                             5                       1   \n",
       "...                         ...                     ...   \n",
       "10122                         3                       2   \n",
       "10123                         4                       2   \n",
       "10124                         5                       3   \n",
       "10125                         4                       3   \n",
       "10126                         6                       2   \n",
       "\n",
       "       Contacts_Count_12_mon  ...  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  \\\n",
       "0                          3  ...                 1.335             1144   \n",
       "1                          2  ...                 1.541             1291   \n",
       "2                          0  ...                 2.594             1887   \n",
       "3                          1  ...                 1.405             1171   \n",
       "4                          0  ...                 2.175              816   \n",
       "...                      ...  ...                   ...              ...   \n",
       "10122                      3  ...                 0.703            15476   \n",
       "10123                      3  ...                 0.804             8764   \n",
       "10124                      4  ...                 0.819            10291   \n",
       "10125                      3  ...                 0.535             8395   \n",
       "10126                      4  ...                 0.703            10294   \n",
       "\n",
       "       Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Gender_F  \\\n",
       "0                  42                1.625                  0.061         0   \n",
       "1                  33                3.714                  0.105         1   \n",
       "2                  20                2.333                  0.000         0   \n",
       "3                  20                2.333                  0.760         1   \n",
       "4                  28                2.500                  0.000         0   \n",
       "...               ...                  ...                    ...       ...   \n",
       "10122             117                0.857                  0.462         0   \n",
       "10123              69                0.683                  0.511         0   \n",
       "10124              60                0.818                  0.000         1   \n",
       "10125              62                0.722                  0.000         0   \n",
       "10126              61                0.649                  0.189         1   \n",
       "\n",
       "       Gender_M  Marital_Status_Divorced  Marital_Status_Married  \\\n",
       "0             1                        0                       1   \n",
       "1             0                        0                       0   \n",
       "2             1                        0                       1   \n",
       "3             0                        0                       0   \n",
       "4             1                        0                       1   \n",
       "...         ...                      ...                     ...   \n",
       "10122         1                        0                       0   \n",
       "10123         1                        1                       0   \n",
       "10124         0                        0                       1   \n",
       "10125         1                        0                       0   \n",
       "10126         0                        0                       1   \n",
       "\n",
       "       Marital_Status_Single  \n",
       "0                          0  \n",
       "1                          1  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "10122                      1  \n",
       "10123                      0  \n",
       "10124                      0  \n",
       "10125                      0  \n",
       "10126                      0  \n",
       "\n",
       "[10127 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data1 = bank_data.replace('Unknown', np.nan)\n",
    "\n",
    "card_cate_map = {'Blue': 0, 'Silver': 1, 'Gold':2, 'Platinum': 3}\n",
    "for i in range(len(bank_data1['Card_Category'])):\n",
    "    for j in card_cate_map:\n",
    "        if bank_data1['Card_Category'][i] == j:\n",
    "            bank_data1.at[i, 'Card_Category'] = card_cate_map[j]       \n",
    "\n",
    "#Transfer education category to integers, because there is a hierarical relationship\n",
    "education_cate_map = {'Uneducated':0,'High School':1,'College':2,'Graduate':3,'Post-Graduate':4, 'Doctorate':5 }\n",
    "for i in range(len(bank_data1['Education_Level'])):\n",
    "    for j in education_cate_map:\n",
    "        if bank_data1['Education_Level'][i] == j:\n",
    "            bank_data1.at[i, 'Education_Level'] = education_cate_map[j]\n",
    "\n",
    "income_cate_map = { 'Less than $40K': 0, '$40K - $60K': 1, '$60K - $80K': 2, '$80K - $120K':3, '$120K +': 4}\n",
    "for i in range(len(bank_data1['Income_Category'])):\n",
    "    for j in income_cate_map:\n",
    "        if bank_data1['Income_Category'][i] == j:\n",
    "            bank_data1.at[i, 'Income_Category'] = income_cate_map[j]\n",
    "            \n",
    "attrition_flag_map = {'Existing Customer': 0, 'Attrited Customer': 1}\n",
    "for i in range(len(bank_data1['Attrition_Flag'])):\n",
    "    for j in attrition_flag_map:\n",
    "        if bank_data1['Attrition_Flag'][i] == j:\n",
    "            bank_data1.at[i, 'Attrition_Flag'] = attrition_flag_map[j]\n",
    "            \n",
    "data1 = pd.get_dummies(bank_data1, columns = ['Gender','Marital_Status'])\n",
    "\n",
    "data1.fillna(data1.mean(), inplace=True)\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b752b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>15476</td>\n",
       "      <td>117</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8764</td>\n",
       "      <td>69</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>10291</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8395</td>\n",
       "      <td>62</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>10294</td>\n",
       "      <td>61</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10127 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attrition_Flag  Customer_Age  Dependent_count Education_Level  \\\n",
       "0                  0            45                3               1   \n",
       "1                  0            49                5               3   \n",
       "2                  0            51                3               3   \n",
       "3                  0            40                4               1   \n",
       "4                  0            40                3               0   \n",
       "...              ...           ...              ...             ...   \n",
       "10122              0            50                2               3   \n",
       "10123              1            41                2             NaN   \n",
       "10124              1            44                1               1   \n",
       "10125              1            30                2               3   \n",
       "10126              1            43                2               3   \n",
       "\n",
       "      Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "0                   2             0              39                         5   \n",
       "1                   0             0              44                         6   \n",
       "2                   3             0              36                         4   \n",
       "3                   0             0              34                         3   \n",
       "4                   2             0              21                         5   \n",
       "...               ...           ...             ...                       ...   \n",
       "10122               1             0              40                         3   \n",
       "10123               1             0              25                         4   \n",
       "10124               0             0              36                         5   \n",
       "10125               1             0              36                         4   \n",
       "10126               0             1              25                         6   \n",
       "\n",
       "       Months_Inactive_12_mon  Contacts_Count_12_mon  ...  Total_Trans_Amt  \\\n",
       "0                           1                      3  ...             1144   \n",
       "1                           1                      2  ...             1291   \n",
       "2                           1                      0  ...             1887   \n",
       "3                           4                      1  ...             1171   \n",
       "4                           1                      0  ...              816   \n",
       "...                       ...                    ...  ...              ...   \n",
       "10122                       2                      3  ...            15476   \n",
       "10123                       2                      3  ...             8764   \n",
       "10124                       3                      4  ...            10291   \n",
       "10125                       3                      3  ...             8395   \n",
       "10126                       2                      4  ...            10294   \n",
       "\n",
       "       Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Gender_F  \\\n",
       "0                  42                1.625                  0.061         0   \n",
       "1                  33                3.714                  0.105         1   \n",
       "2                  20                2.333                  0.000         0   \n",
       "3                  20                2.333                  0.760         1   \n",
       "4                  28                2.500                  0.000         0   \n",
       "...               ...                  ...                    ...       ...   \n",
       "10122             117                0.857                  0.462         0   \n",
       "10123              69                0.683                  0.511         0   \n",
       "10124              60                0.818                  0.000         1   \n",
       "10125              62                0.722                  0.000         0   \n",
       "10126              61                0.649                  0.189         1   \n",
       "\n",
       "       Gender_M  Marital_Status_Divorced  Marital_Status_Married  \\\n",
       "0             1                        0                       1   \n",
       "1             0                        0                       0   \n",
       "2             1                        0                       1   \n",
       "3             0                        0                       0   \n",
       "4             1                        0                       1   \n",
       "...         ...                      ...                     ...   \n",
       "10122         1                        0                       0   \n",
       "10123         1                        1                       0   \n",
       "10124         0                        0                       1   \n",
       "10125         1                        0                       0   \n",
       "10126         0                        0                       1   \n",
       "\n",
       "       Marital_Status_Single  Marital_Status_Unknown  \n",
       "0                          0                       0  \n",
       "1                          1                       0  \n",
       "2                          0                       0  \n",
       "3                          0                       1  \n",
       "4                          0                       0  \n",
       "...                      ...                     ...  \n",
       "10122                      1                       0  \n",
       "10123                      0                       0  \n",
       "10124                      0                       0  \n",
       "10125                      0                       1  \n",
       "10126                      0                       0  \n",
       "\n",
       "[10127 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data2 = bank_data\n",
    "\n",
    "#Transfer card category to integers, because there is a hierarical relationship\n",
    "card_cate_map = {'Blue': 0, 'Silver': 1, 'Gold':2, 'Platinum': 3}\n",
    "for i in range(len(bank_data2['Card_Category'])):\n",
    "    for j in card_cate_map:\n",
    "        if bank_data2['Card_Category'][i] == j:\n",
    "            bank_data2.at[i, 'Card_Category'] = card_cate_map[j]       \n",
    "\n",
    "#Transfer education category to integers, because there is a hierarical relationship\n",
    "education_cate_map = {'Unknown':np.nan,'Uneducated':0,'High School':1,'College':2,'Graduate':3,'Post-Graduate':4, 'Doctorate':5 }\n",
    "for i in range(len(bank_data2['Education_Level'])):\n",
    "    for j in education_cate_map:\n",
    "        if bank_data2['Education_Level'][i] == j:\n",
    "            bank_data2.at[i, 'Education_Level'] = education_cate_map[j]\n",
    "\n",
    "income_cate_map = {'Unknown': np.nan, 'Less than $40K': 0, '$40K - $60K': 1, '$60K - $80K': 2, '$80K - $120K':3, '$120K +': 4}\n",
    "for i in range(len(bank_data2['Income_Category'])):\n",
    "    for j in income_cate_map:\n",
    "        if bank_data2['Income_Category'][i] == j:\n",
    "            bank_data2.at[i, 'Income_Category'] = income_cate_map[j]\n",
    "            \n",
    "attrition_flag_map = {'Existing Customer': 0, 'Attrited Customer': 1}\n",
    "for i in range(len(bank_data2['Attrition_Flag'])):\n",
    "    for j in attrition_flag_map:\n",
    "        if bank_data2['Attrition_Flag'][i] == j:\n",
    "            bank_data2.at[i, 'Attrition_Flag'] = attrition_flag_map[j]\n",
    "            \n",
    "data_pd = pd.get_dummies(bank_data2, columns = ['Gender','Marital_Status'])\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf6f774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_np = data_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b7ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = IterativeImputer(random_state=0)\n",
    "imp_mean.fit(data_np)\n",
    "IterativeImputer(random_state=0)\n",
    "data2 = imp_mean.transform(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9a6cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_sum = np.sum(data2)\n",
    "array_has_nan = np.isnan(array_sum)\n",
    "array_has_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfa01cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X = data2[:, 1:]\n",
    "y = data2[:, 0]\n",
    "\n",
    "# Use LabelEncoder to transform target values into integers.\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(type_of_target(y))\n",
    "print(y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f169c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 columns to be dropped\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data with the StandardScalar\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "\n",
    "# Removes highly correlated data\n",
    "X = pd.DataFrame(X)\n",
    "cor_matrix = X.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.90)]\n",
    "print(\"There are \" + str(len(to_drop)) + \" columns to be dropped\")\n",
    "X = X.drop(X.columns[to_drop], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5445465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict={}\n",
    "high_low_dict = {}\n",
    "    \n",
    "def feature_importance(name, model):\n",
    "    model.fit(X, y)\n",
    "    temp_dict={}\n",
    "    if name == \"SVM Linear\":\n",
    "        importance = [abs(model.coef_[0][i]) for i in range(len(model.coef_[0]))]\n",
    "    else:\n",
    "        importance = model.feature_importances_\n",
    "    for i,v in enumerate(importance):\n",
    "        temp_dict['Feature ' + str(i)] = v\n",
    "        feature_dict[name + ' Feature'] = temp_dict\n",
    "    plt.bar([x for x in range(len(importance))], importance)\n",
    "    plt.show()\n",
    "\n",
    "def high_low_feature(feature_dict):\n",
    "    final_dict={}\n",
    "    for i in feature_dict:\n",
    "        temp_dict={}\n",
    "        max_key = max(feature_dict[i], key=feature_dict[i].get)\n",
    "        max_value = max(feature_dict[i].values())\n",
    "        temp_dict[max_key] = max_value\n",
    "        final_dict[i] = temp_dict\n",
    "    print(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7807533d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model running is: xgboost\n",
      "[20:03:57] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xgboost Feature': {'Feature 13': 0.2185927}}\n",
      "[20:03:58] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:03:58] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:03:58] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:03:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:03:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "the score is 0.9716592446345654 with std of 0.004292635347375812\n",
      "[20:04:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(10127,)\n",
      "auc 0.9713289916108081 got added\n",
      "[20:04:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:04] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:04] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuandou/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      8500\n",
      "           1       0.94      0.89      0.91      1627\n",
      "\n",
      "    accuracy                           0.97     10127\n",
      "   macro avg       0.96      0.94      0.95     10127\n",
      "weighted avg       0.97      0.97      0.97     10127\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                8403                  97\n",
      "Actual Positive                 185                1442\n",
      "\n",
      "The FN is  185\n",
      "The tn is  8403\n",
      "The tp is  1442\n",
      "The fp is  97\n",
      "\n",
      "The precision is:  0.9369720597790773\n",
      "The recall is:  0.8862937922556853\n",
      "The f1 score is:  0.9109286165508529\n",
      "Area under the Receiver Operating Characteristic curve: 0.9374410137749015\n",
      "\n",
      "The averagve area under the precision-recall curve is: 0.9713289916108081 with std of 0.0\n",
      "\n",
      "The average accuracy is 0.9716592446345654 with the std of 0.004292635347375812\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define the scoring method\n",
    "scoring = 'accuracy'\n",
    "number_repeat = 1 #minimum is 1\n",
    "score_dict = {}\n",
    "auc_dict = {}\n",
    "\n",
    "# define models to train\n",
    "names = [\n",
    "#        'Decision Tree',\n",
    "#          'SVM Linear',\n",
    "#          'SVM RBF', \n",
    "#          'SVM Sigmoid'\n",
    "#         'BaggingClassifier',\n",
    "#         'RandomForest',\n",
    "#         'Adaboost',\n",
    "            'xgboost'\n",
    "        ]\n",
    "\n",
    "# build classifiers\n",
    "classifiers = [\n",
    "#     tree.DecisionTreeClassifier(),\n",
    "#     SVC(kernel='linear', C = 2.0, gamma='scale'),\n",
    "#     SVC(kernel='rbf', C = 2.0, gamma='scale'),\n",
    "#     SVC(kernel='sigmoid', C = 2.0, gamma='scale'),\n",
    "#     BaggingClassifier(n_estimators=200, oob_score = True),\n",
    "#     RandomForestClassifier(n_estimators=300, max_features = \"sqrt\", oob_score = True),\n",
    "#     AdaBoostClassifier(n_estimators=400, learning_rate = 0.6)\n",
    "     xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric='mlogloss', random_state=42, use_label_encoder=False)\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "#results_2 = []\n",
    "#results_3 = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Use stratified k-fold cross validation to deal with imbalanced data\n",
    "    print(\"The model running is: \" + name)\n",
    "    \n",
    "    if name != \"BaggingClassifier\":\n",
    "        feature_importance(name, model)\n",
    "    high_low_feature(feature_dict)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for i in range(number_repeat):\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        scores = cross_val_score(model, X, y, cv = kfold)\n",
    "        if name not in score_dict:\n",
    "            score_dict[name] = [] \n",
    "        score_dict[name].append((scores.mean(), scores.std()))\n",
    "        print(\"the score is\", scores.mean(),\"with std of\", scores.std())\n",
    "        y_pred = cross_val_predict(model, X, y, cv=kfold, method='predict_proba')[:,1]\n",
    "#         y_pred = model.fit(X,y).predict_proba(X)\n",
    "        print(y_pred.shape)\n",
    "        if name not in auc_dict:\n",
    "            auc_dict[name] = [] \n",
    "        precision, recall, thresholds = precision_recall_curve(y, y_pred)\n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "        auc_dict[name].append(auc_precision_recall)\n",
    "        print(\"auc\", auc_precision_recall, \"got added\")\n",
    "    \n",
    "#     y_pred = model.fit(X,y).predict_proba(X)[:,1]\n",
    "    y_classification = cross_val_predict(model, X, y, cv=kfold)\n",
    "    y_pred = cross_val_predict(model, X, y, cv=kfold,method='predict_proba')[:,1]\n",
    "    print(classification_report(y, y_classification))\n",
    "    \n",
    "    confusion_mat = confusion_matrix(y, y_classification)\n",
    "    graph = pd.DataFrame(confusion_mat, \n",
    "             columns=['Predicted Negative', 'Predicted Positive'], \n",
    "             index=['Actual Negative', 'Actual Positive'])\n",
    "    \n",
    "    print(graph)\n",
    "    print()\n",
    "    fn = confusion_mat[1][0]\n",
    "    tn = confusion_mat[0][0]\n",
    "    tp = confusion_mat[1][1]\n",
    "    fp = confusion_mat[0][1] \n",
    "    \n",
    "    print(\"The FN is \", fn)\n",
    "    print(\"The tn is \", tn)\n",
    "    print(\"The tp is \", tp)\n",
    "    print(\"The fp is \", fp)\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall / (precision + recall))\n",
    "    \n",
    "    print()\n",
    "    print(\"The precision is: \", precision)\n",
    "    print(\"The recall is: \", recall)\n",
    "    print(\"The f1 score is: \", f1_score)\n",
    "\n",
    "    print('Area under the Receiver Operating Characteristic curve:', str(roc_auc_score(y, y_classification)))\n",
    "    print()\n",
    "    auc_precision_recall_mean = sum(auc_dict[name]) / len(auc_dict[name])\n",
    "    auc_precision_recall_std = statistics.pstdev(auc_dict[name])\n",
    "    print(\"The averagve area under the precision-recall curve is:\", auc_precision_recall_mean, \"with std of\", auc_precision_recall_std)\n",
    "    print()\n",
    "    temp_list = score_dict[name]\n",
    "    score_mean = 0\n",
    "    score_std = 0\n",
    "    for i in temp_list:\n",
    "        score_mean += i[0]\n",
    "        score_std += i[1]\n",
    "    score_mean /= len(temp_list)\n",
    "    score_std /= len(temp_list)\n",
    "    print(\"The average accuracy is\",score_mean,\"with the std of\",score_std)\n",
    "    print()\n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_pred)\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"Precision-Recall curve of \" + name)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
