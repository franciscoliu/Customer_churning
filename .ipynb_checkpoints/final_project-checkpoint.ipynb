{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136f5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d06c78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BankChurners.csv\").drop(columns = ['CLIENTNUM'])\n",
    "bank_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09724b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition_Flag ['Existing Customer' 'Attrited Customer']\n",
      "Customer_Age [45 49 51 40 44 32 37 48 42 65 56 35 57 41 61 47 62 54 59 63 53 58 55 66\n",
      " 50 38 46 52 39 43 64 68 67 60 73 70 36 34 33 26 31 29 30 28 27]\n",
      "Gender ['M' 'F']\n",
      "Dependent_count [3 5 4 2 0 1]\n",
      "Education_Level ['High School' 'Graduate' 'Uneducated' 'Unknown' 'College' 'Post-Graduate'\n",
      " 'Doctorate']\n",
      "Marital_Status ['Married' 'Single' 'Unknown' 'Divorced']\n",
      "Income_Category ['$60K - $80K' 'Less than $40K' '$80K - $120K' '$40K - $60K' '$120K +'\n",
      " 'Unknown']\n",
      "Card_Category ['Blue' 'Gold' 'Silver' 'Platinum']\n",
      "Months_on_book [39 44 36 34 21 46 27 31 54 30 48 37 56 42 49 33 28 38 41 43 45 52 40 50\n",
      " 35 47 32 20 29 25 53 24 55 23 22 26 13 51 19 15 17 18 16 14]\n",
      "Total_Relationship_Count [5 6 4 3 2 1]\n",
      "Months_Inactive_12_mon [1 4 2 3 6 0 5]\n",
      "Contacts_Count_12_mon [3 2 0 1 4 5 6]\n",
      "Credit_Limit [12691.  8256.  3418. ...  5409.  5281. 10388.]\n",
      "Total_Revolving_Bal [ 777  864    0 ...  534  476 2241]\n",
      "Avg_Open_To_Buy [11914.  7392.  3418. ... 11831.  5409.  8427.]\n",
      "Total_Amt_Chng_Q4_Q1 [1.335 1.541 2.594 ... 0.222 0.204 0.166]\n",
      "Total_Trans_Amt [ 1144  1291  1887 ... 10291  8395 10294]\n",
      "Total_Trans_Ct [ 42  33  20  28  24  31  36  32  26  17  29  27  21  30  16  18  23  22\n",
      "  40  38  25  43  37  19  35  15  41  57  12  14  34  44  13  47  10  39\n",
      "  53  50  52  48  49  45  11  55  46  54  60  51  63  58  59  61  78  64\n",
      "  65  62  67  66  56  69  71  75  74  76  84  82  88  68  70  73  86  72\n",
      "  79  80  85  81  87  83  91  89  77 103  93  96  99  92  90  94  95  98\n",
      " 100 102  97 101 104 105 106 107 109 118 108 122 113 112 111 127 114 124\n",
      " 110 120 125 121 117 126 134 116 119 129 131 115 128 139 123 130 138 132]\n",
      "Total_Ct_Chng_Q4_Q1 [1.625 3.714 2.333 2.5   0.846 0.722 0.714 1.182 0.882 0.68  1.364 3.25\n",
      " 2.    0.611 1.7   0.929 1.143 0.909 0.6   1.571 0.353 0.75  0.833 1.3\n",
      " 1.    0.9   2.571 1.6   1.667 0.483 1.176 1.2   0.556 0.143 0.474 0.917\n",
      " 1.333 0.588 0.8   1.923 0.25  0.364 1.417 1.083 1.25  0.5   1.154 0.733\n",
      " 0.667 2.4   1.05  0.286 0.4   0.522 0.435 1.875 0.966 1.412 0.526 0.818\n",
      " 1.8   1.636 2.182 0.619 0.933 1.222 0.304 0.727 0.385 1.5   0.789 0.542\n",
      " 1.1   1.095 0.824 0.391 0.346 3.    1.056 1.118 0.786 0.625 1.533 0.382\n",
      " 0.355 0.765 0.778 2.2   1.545 0.7   1.211 1.231 0.636 0.455 2.875 1.308\n",
      " 0.467 1.909 0.571 0.812 2.429 0.706 2.167 0.263 0.429 2.286 0.828 1.467\n",
      " 0.478 0.867 0.88  1.444 1.273 0.941 0.684 0.591 0.762 0.529 0.615 0.519\n",
      " 0.421 0.947 1.167 1.105 0.737 1.263 0.538 1.071 0.357 0.407 0.923 1.455\n",
      " 0.35  2.273 0.69  0.65  0.167 0.647 1.615 0.545 0.875 1.125 0.462 1.294\n",
      " 1.357 3.5   1.067 1.286 0.524 1.214 0.273 1.538 0.783 0.235 0.607 2.083\n",
      " 0.632 0.368 0.444 0.76  0.536 0.438 0.423 2.1   0.565 0.719 0.182 1.75\n",
      " 0.944 0.581 0.333 0.643 0.87  0.692 1.227 0.938 1.833 0.652 1.462 0.583\n",
      " 0.679 0.375 1.091 2.75  1.385 1.188 0.261 1.312 0.656 1.235 0.958 0.37\n",
      " 0.059 0.3   0.613 1.778 0.955 0.864 1.429 0.889 1.438 0.481 0.452 1.13\n",
      " 0.562 1.048 0.409 0.622 0.688 1.217 0.211 0.606 0.655 0.381 1.053 1.316\n",
      " 0.575 0.85  0.41  0.609 1.579 0.56  0.276 0.533 0.515 0.308 0.852 0.371\n",
      " 0.214 0.63  0.231 0.406 0.405 0.349 0.857 0.212 0.543 1.059 0.579 0.387\n",
      " 0.724 0.415 0.895 0.781 0.412 0.649 0.32  0.345 0.367 0.586 0.324 0.306\n",
      " 0.676 0.708 0.476 0.29  0.55  0.133 0.344 0.52  0.471 0.842 0.654 0.516\n",
      " 0.464 1.857 0.629 0.963 0.686 0.323 0.585 0.633 0.92  0.441 0.424 0.59\n",
      " 0.763 0.207 0.314 2.222 1.45  0.469 3.571 0.696 0.741 0.512 1.043 0.568\n",
      " 0.548 0.194 0.552 0.448 0.651 0.393 0.657 0.682 0.808 1.032 0.577 0.241\n",
      " 0.425 0.348 0.318 0.292 0.312 0.486 0.969 0.697 0.389 0.44  0.829 0.677\n",
      " 0.189 0.259 0.72  0.815 1.15  0.806 0.537 0.721 0.531 0.472 0.594 0.773\n",
      " 0.826 0.906 0.417 0.758 1.107 0.621 0.458 0.267 0.107 0.459 0.71  0.487\n",
      " 0.95  0.321 0.414 0.742 0.739 0.767 0.394 0.091 0.926 0.618 0.784 0.208\n",
      " 1.136 0.897 0.593 0.294 0.718 1.375 0.862 0.439 0.839 0.595 1.208 0.96\n",
      " 0.514 0.433 0.484 1.08  0.931 0.233 0.971 0.957 1.038 0.48  0.731 1.474\n",
      " 1.062 0.608 1.103 1.111 0.725 1.647 0.774 0.477 0.238 0.967 0.769 0.576\n",
      " 0.567 1.042 0.759 0.81  1.069 0.574 0.528 0.278 0.703 0.447 0.028 0.297\n",
      " 1.037 0.269 0.962 0.905 0.111 0.513 0.31  0.614 0.436 0.45  1.48  0.296\n",
      " 0.879 1.114 0.262 1.278 0.257 0.517 1.36  0.605 1.04  0.711 0.844 0.623\n",
      " 0.913 0.756 1.045 0.775 0.645 0.793 0.488 0.511 0.811 0.838 0.641 0.646\n",
      " 0.972 0.559 0.659 0.525 0.038 0.871 0.919 0.179 0.639 0.077 0.564 0.419\n",
      " 0.853 0.64  0.848 1.033 0.351 0.675 0.743 0.952 1.077 1.087 1.12  0.885\n",
      " 0.592 0.893 0.265 1.292 0.457 0.771 0.977 0.053 1.318 0.809 0.674 0.968\n",
      " 0.316 0.15  0.558 0.485 0.735 0.275 0.19  1.381 0.379 0.689 0.561 0.174\n",
      " 0.217 1.174 0.766 0.683 0.    0.281 0.28  0.492 0.788 0.865 0.881 0.794\n",
      " 0.712 0.658 0.891 1.24  0.911 0.946 0.2   0.465 0.489 0.541 0.86  0.628\n",
      " 0.062 0.795 1.722 0.892 0.578 0.704 0.732 0.587 0.956 0.185 0.341 0.58\n",
      " 0.378 1.036 0.549 0.491 0.702 0.638 0.176 0.912 0.535 0.521 0.653 0.604\n",
      " 0.73  0.66  1.139 0.509 1.882 0.463 0.634 0.694 1.148 0.757 1.35  0.362\n",
      " 0.822 0.755 0.395 0.861 0.738 1.133 0.872 0.886 1.156 0.532 1.03  0.453\n",
      " 0.821 1.034 0.635 0.154 0.903 1.207 1.31  0.523 0.878 0.744 0.317 0.93\n",
      " 0.24  0.804 0.761 0.54  0.479 0.551 1.4   0.553 0.426 0.816 0.698 0.227\n",
      " 0.896 0.792 1.051 0.61  0.884 0.408 0.617 0.935 0.361 0.902 0.78  0.841\n",
      " 0.796 0.975 1.081 0.707 0.422 0.964 0.172 0.805 0.717 0.347 1.138 0.791\n",
      " 0.681 0.256 1.609 0.868 0.468 0.432 1.121 0.787 0.596 0.976 1.158 1.028\n",
      " 0.949 0.451 0.456 0.837 1.212 0.673 0.222 0.171 0.51  0.685 0.396 0.388\n",
      " 0.644 0.914 1.476 0.46  0.547 1.421 0.825 0.729 0.723 1.471 0.939 0.974\n",
      " 0.943 0.84  0.627 0.13  1.147 0.327 1.065 0.705 1.37  0.854 0.951 0.569\n",
      " 0.921 0.776 0.927 0.449 0.475 0.97  1.097 0.612 1.024 1.088 0.648 0.242\n",
      " 0.661 0.745 1.522 0.843 0.907 1.027 1.783 0.62  0.814 1.026 0.851 1.094\n",
      " 0.431 1.057 0.226 0.736 0.103 1.29  0.925 0.566 0.161 0.303 1.152 1.65\n",
      " 0.74  1.194 1.226 0.642 1.323 1.025 1.074 0.508 0.49  0.534 0.83  0.978\n",
      " 1.206 1.054 0.936 0.932 0.105 1.061 1.031 1.478 0.898 0.672 0.188 0.518\n",
      " 0.953 1.049 1.086 0.691 0.411 1.029 1.419 1.075 0.206 0.973 1.219 1.162\n",
      " 0.827 1.321 0.343 0.764 0.125 0.119 1.189 1.179 1.258 1.229 1.073 0.074\n",
      " 1.458 1.172 1.32  1.108 1.16  0.36  1.391 1.583 0.147 1.115 0.359 1.128\n",
      " 0.915 0.282 0.162 1.303 0.582 1.382 1.171 0.029 1.161 0.192 1.346 0.473\n",
      " 0.097 0.82  0.557 0.894 1.135 1.367 1.023 0.544 0.589 0.603 0.442 0.295\n",
      " 0.434 0.554 0.372 0.527 0.709 0.782 0.797 0.695 0.849 0.768 0.863 0.746\n",
      " 0.597 0.631 0.678 0.887 0.754 0.687 0.699 0.873 0.716 0.934 0.847 0.244\n",
      " 0.803 0.772 0.859 1.064 0.819 0.573 0.807 0.79  0.817 0.785 0.823 0.836\n",
      " 0.616 0.831 1.06  1.122 0.866 0.662 0.869 0.779 0.981 0.293 0.855 0.98\n",
      " 0.671 1.079 0.693 0.77  1.093 1.018 1.022 0.734 0.753 0.726 0.922 0.948\n",
      " 1.684 0.918]\n",
      "Avg_Utilization_Ratio [0.061 0.105 0.    0.76  0.311 0.066 0.048 0.113 0.144 0.217 0.174 0.195\n",
      " 0.279 0.23  0.078 0.095 0.788 0.08  0.086 0.152 0.626 0.215 0.093 0.099\n",
      " 0.285 0.658 0.69  0.282 0.562 0.135 0.544 0.757 0.241 0.077 0.018 0.355\n",
      " 0.145 0.209 0.793 0.074 0.259 0.591 0.687 0.127 0.667 0.843 0.422 0.156\n",
      " 0.525 0.587 0.211 0.088 0.111 0.044 0.276 0.704 0.656 0.053 0.051 0.467\n",
      " 0.698 0.067 0.079 0.287 0.36  0.256 0.719 0.198 0.14  0.035 0.619 0.108\n",
      " 0.062 0.765 0.963 0.524 0.347 0.45  0.232 0.299 0.085 0.059 0.43  0.62\n",
      " 0.027 0.169 0.058 0.223 0.057 0.513 0.473 0.047 0.106 0.05  0.03  0.615\n",
      " 0.15  0.407 0.191 0.096 0.176 0.83  0.412 0.678 0.246 0.271 0.114 0.395\n",
      " 0.406 0.258 0.178 0.941 0.141 0.118 0.119 0.64  0.432 0.612 0.359 0.309\n",
      " 0.101 0.607 0.512 0.806 0.463 0.77  0.076 0.133 0.037 0.146 0.171 0.069\n",
      " 0.837 0.055 0.294 0.39  0.19  0.692 0.503 0.251 0.11  0.087 0.214 0.164\n",
      " 0.049 0.043 0.679 0.098 0.694 0.039 0.199 0.22  0.13  0.202 0.319 0.165\n",
      " 0.863 0.665 0.598 0.539 0.472 0.064 0.16  0.42  0.713 0.092 0.336 0.666\n",
      " 0.147 0.987 0.073 0.88  0.28  0.65  0.761 0.072 0.327 0.459 0.252 0.244\n",
      " 0.291 0.46  0.489 0.482 0.24  0.197 0.866 0.317 0.762 0.162 0.196 0.734\n",
      " 0.446 0.262 0.042 0.094 0.308 0.68  0.238 0.753 0.877 0.724 0.117 0.638\n",
      " 0.102 0.131 0.255 0.716 0.609 0.405 0.154 0.605 0.275 0.06  0.07  0.186\n",
      " 0.648 0.167 0.153 0.79  0.732 0.123 0.221 0.2   0.063 0.785 0.771 0.224\n",
      " 0.795 0.187 0.583 0.316 0.447 0.625 0.514 0.557 0.955 0.867 0.846 0.756\n",
      " 0.31  0.373 0.935 0.155 0.435 0.932 0.829 0.953 0.188 0.82  0.616 0.595\n",
      " 0.521 0.268 0.09  0.885 0.546 0.569 0.183 0.639 0.329 0.274 0.161 0.865\n",
      " 0.73  0.134 0.137 0.478 0.361 0.312 0.036 0.243 0.805 0.168 0.103 0.179\n",
      " 0.529 0.227 0.706 0.075 0.804 0.708 0.766 0.381 0.046 0.428 0.112 0.041\n",
      " 0.85  0.517 0.72  0.056 0.548 0.436 0.201 0.523 0.081 0.403 0.671 0.752\n",
      " 0.194 0.657 0.476 0.729 0.911 0.78  0.35  0.636 0.632 0.226 0.798 0.781\n",
      " 0.148 0.029 0.12  0.651 0.257 0.204 0.231 0.18  0.617 0.458 0.142 0.054\n",
      " 0.374 0.491 0.216 0.572 0.32  0.212 0.545 0.314 0.393 0.599 0.33  0.663\n",
      " 0.159 0.185 0.371 0.506 0.448 0.128 0.269 0.333 0.125 0.091 0.53  0.303\n",
      " 0.682 0.456 0.584 0.337 0.51  0.819 0.543 0.81  0.189 0.213 0.068 0.033\n",
      " 0.261 0.071 0.41  0.712 0.515 0.593 0.203 0.286 0.457 0.654 0.122 0.345\n",
      " 0.825 0.1   0.206 0.976 0.17  0.292 0.139 0.109 0.278 0.324 0.745 0.402\n",
      " 0.397 0.045 0.177 0.611 0.284 0.578 0.318 0.803 0.594 0.684 0.019 0.722\n",
      " 0.032 0.115 0.511 0.306 0.104 0.219 0.709 0.621 0.082 0.553 0.465 0.707\n",
      " 0.166 0.859 0.677 0.253 0.586 0.425 0.801 0.084 0.645 0.149 0.343 0.878\n",
      " 0.304 0.814 0.342 0.848 0.163 0.222 0.469 0.519 0.272 0.325 0.702 0.181\n",
      " 0.693 0.809 0.479 0.468 0.356 0.811 0.34  0.63  0.372 0.637 0.507 0.749\n",
      " 0.129 0.674 0.794 0.582 0.464 0.065 0.315 0.691 0.501 0.218 0.56  0.175\n",
      " 0.5   0.378 0.613 0.313 0.727 0.239 0.603 0.57  0.27  0.034 0.247 0.737\n",
      " 0.124 0.589 0.534 0.237 0.136 0.789 0.777 0.52  0.653 0.016 0.346 0.721\n",
      " 0.675 0.138 0.266 0.442 0.326 0.301 0.717 0.023 0.025 0.25  0.281 0.796\n",
      " 0.296 0.334 0.471 0.571 0.352 0.143 0.608 0.775 0.67  0.321 0.696 0.689\n",
      " 0.624 0.408 0.157 0.439 0.672 0.302 0.225 0.357 0.527 0.431 0.831 0.755\n",
      " 0.786 0.026 0.659 0.416 0.451 0.052 0.404 0.394 0.391 0.736 0.854 0.791\n",
      " 0.126 0.363 0.874 0.297 0.341 0.344 0.208 0.733 0.234 0.116 0.828 0.365\n",
      " 0.182 0.384 0.526 0.396 0.031 0.516 0.748 0.354 0.349 0.233 0.497 0.248\n",
      " 0.339 0.132 0.588 0.764 0.705 0.575 0.536 0.021 0.205 0.835 0.549 0.74\n",
      " 0.889 0.083 0.596 0.735 0.827 0.522 0.711 0.377 0.351 0.242 0.366 0.697\n",
      " 0.328 0.778 0.743 0.492 0.715 0.623 0.488 0.263 0.568 0.089 0.779 0.47\n",
      " 0.264 0.415 0.58  0.452 0.289 0.635 0.229 0.75  0.695 0.6   0.784 0.173\n",
      " 0.822 0.812 0.265 0.574 0.475 0.295 0.662 0.3   0.566 0.994 0.669 0.04\n",
      " 0.856 0.532 0.461 0.559 0.331 0.602 0.445 0.466 0.597 0.646 0.474 0.305\n",
      " 0.556 0.742 0.631 0.718 0.606 0.647 0.758 0.644 0.499 0.873 0.245 0.487\n",
      " 0.558 0.49  0.121 0.869 0.797 0.437 0.772 0.7   0.934 0.857 0.015 0.547\n",
      " 0.353 0.699 0.495 0.409 0.29  0.293 0.494 0.477 0.235 0.894 0.417 0.881\n",
      " 0.207 0.928 0.484 0.852 0.038 0.228 0.643 0.655 0.283 0.642 0.581 0.379\n",
      " 0.542 0.579 0.434 0.44  0.535 0.913 0.776 0.551 0.401 0.273 0.172 0.375\n",
      " 0.714 0.668 0.362 0.833 0.633 0.783 0.614 0.763 0.844 0.744 0.61  0.453\n",
      " 0.481 0.563 0.418 0.399 0.348 0.59  0.413 0.498 0.267 0.398 0.386 0.815\n",
      " 0.249 0.429 0.799 0.751 0.821 0.323 0.107 0.807 0.816 0.99  0.573 0.449\n",
      " 0.883 0.768 0.925 0.773 0.38  0.604 0.411 0.832 0.184 0.438 0.552 0.792\n",
      " 0.376 0.641 0.37  0.158 0.426 0.277 0.493 0.629 0.02  0.236 0.21  0.726\n",
      " 0.531 0.92  0.949 0.628 0.731 0.518 0.358 0.554 0.893 0.943 0.944 0.601\n",
      " 0.307 0.725 0.368 0.924 0.661 0.151 0.769 0.576 0.424 0.664 0.024 0.922\n",
      " 0.537 0.884 0.483 0.462 0.899 0.622 0.013 0.954 0.683 0.192 0.774 0.824\n",
      " 0.858 0.984 0.414 0.561 0.879 0.504 0.509 0.968 0.918 0.836 0.332 0.028\n",
      " 0.938 0.541 0.48  0.533 0.528 0.254 0.423 0.288 0.369 0.93  0.813 0.915\n",
      " 0.364 0.688 0.902 0.868 0.942 0.567 0.022 0.703 0.585 0.906 0.754 0.855\n",
      " 0.839 0.681 0.298 0.872 0.455 0.929 0.008 0.388 0.912 0.322 0.853 0.454\n",
      " 0.685 0.747 0.66  0.904 0.738 0.485 0.496 0.577 0.927 0.746 0.565 0.634\n",
      " 0.887 0.845 0.951 0.444 0.427 0.962 0.564 0.851 0.897 0.876 0.421 0.012\n",
      " 0.649 0.759 0.84  0.842 0.87  0.097 0.983 0.433 0.387 0.441 0.767 0.903\n",
      " 0.592 0.895 0.896 0.652 0.8   0.4   0.017 0.862 0.849 0.676 0.999 0.921\n",
      " 0.673 0.948 0.004 0.864 0.55  0.787 0.392 0.443 0.505 0.538 0.71  0.367\n",
      " 0.985 0.741 0.826 0.817 0.508 0.26  0.618 0.94  0.916 0.823 0.9   0.193\n",
      " 0.419 0.841 0.919 0.959 0.723 0.486 0.54  0.905 0.385 0.782 0.006 0.502\n",
      " 0.802 0.875 0.931 0.011 0.926 0.728 0.382 0.335 0.891 0.871 0.701 0.739\n",
      " 0.383 0.834 0.898 0.389 0.901 0.988 0.907 0.686 0.86  0.882 0.861 0.917\n",
      " 0.555 0.808 0.338 0.96  0.972 0.01  0.847 0.964 0.886 0.995 0.818 0.958\n",
      " 0.627 0.992 0.952 0.91  0.978 0.973 0.971 0.945 0.914 0.977 0.956 0.909\n",
      " 0.005 0.007 0.014 0.009]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa0def6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer card category to integers, because there is a hierarical relationship\n",
    "card_cate_map = {'Blue': 0, 'Silver': 1, 'Gold':2, 'Platinum': 3}\n",
    "for i in range(len(bank_data['Card_Category'])):\n",
    "    for j in card_cate_map:\n",
    "        if bank_data['Card_Category'][i] == j:\n",
    "            bank_data.at[i, 'Card_Category'] = card_cate_map[j]       \n",
    "\n",
    "#Transfer education category to integers, because there is a hierarical relationship\n",
    "education_cate_map = {'Unknown':-1,'Uneducated':0,'High School':1,'College':2,'Graduate':3,'Post-Graduate':4, 'Doctorate':5 }\n",
    "for i in range(len(bank_data['Education_Level'])):\n",
    "    for j in education_cate_map:\n",
    "        if bank_data['Education_Level'][i] == j:\n",
    "            bank_data.at[i, 'Education_Level'] = education_cate_map[j]\n",
    "\n",
    "income_cate_map = {'Unknown': -1, 'Less than $40K': 0, '$40K - $60K': 1, '$60K - $80K': 2, '$80K - $120K':3, '$120K +': 4}\n",
    "for i in range(len(bank_data['Income_Category'])):\n",
    "    for j in income_cate_map:\n",
    "        if bank_data['Income_Category'][i] == j:\n",
    "            bank_data.at[i, 'Income_Category'] = income_cate_map[j]\n",
    "            \n",
    "attrition_flag_map = {'Existing Customer': 0, 'Attrited Customer': 1}\n",
    "for i in range(len(bank_data['Attrition_Flag'])):\n",
    "    for j in attrition_flag_map:\n",
    "        if bank_data['Attrition_Flag'][i] == j:\n",
    "            bank_data.at[i, 'Attrition_Flag'] = attrition_flag_map[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44138fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(bank_data, columns = ['Gender','Marital_Status'])\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c5cfffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31020/3725297994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "293a6bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 45, 3, ..., 1, 0, 0],\n",
       "       [0, 49, 5, ..., 0, 1, 0],\n",
       "       [0, 51, 3, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 44, 1, ..., 1, 0, 0],\n",
       "       [1, 30, 2, ..., 0, 0, 1],\n",
       "       [1, 43, 2, ..., 1, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "631c8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "X_train_1 ,X_val_1, y_train_1, y_val_1 = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66e33d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 942, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 203, in fit\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 198, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 716, in _validate_targets\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 198, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Preprocess 1: nan  (nan)\n",
      "SVM Linear:\n",
      "Preprocess 1: nan  (nan)\n",
      "SVM RBF:\n",
      "Preprocess 1: nan  (nan)\n",
      "SVM Sigmoid:\n",
      "Preprocess 1: nan  (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 716, in _validate_targets\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 198, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 199, in fit\n",
      "    y = self._validate_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 716, in _validate_targets\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\lione\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 198, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# define the scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# define models to train\n",
    "names = ['Decision Tree', 'SVM Linear', 'SVM RBF', 'SVM Sigmoid']\n",
    "\n",
    "# build classifiers\n",
    "classifiers = [\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    SVC(kernel='linear', gamma='auto'),\n",
    "    SVC(kernel='rbf', gamma='auto'),\n",
    "    SVC(kernel='sigmoid', gamma='auto'),\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results_1 = []\n",
    "#results_2 = []\n",
    "#results_3 = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    cv_results_1 = cross_val_score(model, X_train_1, y_train_1, cv=kfold, scoring=scoring)\n",
    "    #cv_results_2 = cross_val_score(model, X_train_2, y_train_2, cv=kfold, scoring=scoring)\n",
    "    #cv_results_3 = cross_val_score(model, X_train_3, y_train_3, cv=kfold, scoring=scoring)\n",
    "    results_1.append(cv_results_1)\n",
    "    #results_2.append(cv_results_2)\n",
    "    #results_3.append(cv_results_3)\n",
    "    names.append(name)\n",
    "    #msg = '{0}:\\nPreprocess 1: {1}  ({2})\\nPreprocess 2: {3}  ({4})\\nPreprocess 3: {5}  ({6})'.format(name, cv_results_1.mean(), cv_results_1.std(), cv_results_2.mean(), cv_results_2.std(), cv_results_3.mean(), cv_results_3.std())\n",
    "    msg = '{0}:\\nPreprocess 1: {1}  ({2})'.format(name, cv_results_1.mean(), cv_results_1.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a9863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
